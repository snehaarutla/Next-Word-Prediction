{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a96923f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cc71929",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:/Users/saisn/OneDrive/Desktop/parkinsons.csv\") as file:\n",
    "    data=file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04de6a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "#     non_html=re.sub('<.*?>',' ',x)   \n",
    "#remove html tag using regular expresion\n",
    "soup=BeautifulSoup(data,'html.parser')\n",
    "#remove html tag using beautifulsoup\n",
    "non_html_text=soup.get_text()\n",
    "    \n",
    "#remove unwanted charectors and symbols\n",
    "text=re.sub('[^a-zA-Z0-9\\s]',' ',non_html_text)\n",
    "text = text.replace('\\n', '').replace('\\r', '').replace('\\ufeff', '')\n",
    "\n",
    "#remove extra spaces\n",
    "z = []\n",
    "for i in text.split():\n",
    "    if i not in z:\n",
    "        z.append(i)  \n",
    "text = ' '.join(z)\n",
    "\n",
    "\n",
    "#tokenize text\n",
    "    \n",
    "tokenizer=Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "sequence=tokenizer.texts_to_sequences([text])[0]\n",
    "\n",
    "sequence[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b05b71ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3520"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ip_dim=len(tokenizer.word_index)+1\n",
    "ip_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "702078d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Length of sequences are:  3516\n"
     ]
    }
   ],
   "source": [
    "#traning sequence\n",
    "\n",
    "sequences = []\n",
    "\n",
    "for i in range(3, len(sequence)):\n",
    "    words = sequence[i-3:i+1]\n",
    "    sequences.append(words)\n",
    "    \n",
    "print(\"The Length of sequences are: \", len(sequences))\n",
    "sequences = np.array(sequences)\n",
    "\n",
    "\n",
    "x,y=[],[]\n",
    "for i in sequences:\n",
    "    x.append(i[0:3])\n",
    "    y.append(i[3])\n",
    "x=np.array(x)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc0a960b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1,  2,  3],\n",
       "        [ 2,  3,  4],\n",
       "        [ 3,  4,  5],\n",
       "        [ 4,  5,  6],\n",
       "        [ 5,  6,  7],\n",
       "        [ 6,  7,  8],\n",
       "        [ 7,  8,  9],\n",
       "        [ 8,  9, 10],\n",
       "        [ 9, 10, 11],\n",
       "        [10, 11, 12]]),\n",
       " array([ 4,  5,  6,  7,  8,  9, 10, 11, 12, 13]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:10],y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7790a623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# # # Pad \"sequences\" to a fixed length\n",
    "# max_len = 10\n",
    "# x = pad_sequences(x, maxlen=max_len)\n",
    "# y = pad_sequences(y, maxlen=max_len)\n",
    "\n",
    "# Convert y to categorical\n",
    "\n",
    "y = to_categorical(y, num_classes=ip_dim)\n",
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2705888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 3, 10)             35200     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 3, 1000)           4044000   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 1000)              8004000   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1000)              1001000   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3520)              3523520   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,607,720\n",
      "Trainable params: 16,607,720\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dense,Embedding\n",
    "model=Sequential()\n",
    "model.add(Embedding(ip_dim,10,input_length=3))\n",
    "model.add(LSTM(1000,return_sequences=True))\n",
    "model.add(LSTM(1000))\n",
    "model.add(Dense(1000, activation=\"relu\"))\n",
    "model.add(Dense(ip_dim,activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af7b2572",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1678b2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "57/57 [==============================] - 10s 108ms/step - loss: 8.1776 - accuracy: 0.0000e+00\n",
      "Epoch 2/70\n",
      "57/57 [==============================] - 6s 107ms/step - loss: 8.1691 - accuracy: 0.0000e+00\n",
      "Epoch 3/70\n",
      "57/57 [==============================] - 6s 111ms/step - loss: 8.1689 - accuracy: 0.0000e+00\n",
      "Epoch 4/70\n",
      "57/57 [==============================] - 6s 105ms/step - loss: 8.1688 - accuracy: 0.0000e+00\n",
      "Epoch 5/70\n",
      "57/57 [==============================] - 6s 102ms/step - loss: 8.1688 - accuracy: 0.0000e+00\n",
      "Epoch 6/70\n",
      "57/57 [==============================] - 6s 102ms/step - loss: 8.1687 - accuracy: 0.0000e+00\n",
      "Epoch 7/70\n",
      "57/57 [==============================] - 6s 103ms/step - loss: 8.1687 - accuracy: 0.0000e+00\n",
      "Epoch 8/70\n",
      "57/57 [==============================] - 6s 102ms/step - loss: 8.1686 - accuracy: 0.0000e+00\n",
      "Epoch 9/70\n",
      "57/57 [==============================] - 6s 103ms/step - loss: 8.1686 - accuracy: 0.0000e+00\n",
      "Epoch 10/70\n",
      "57/57 [==============================] - 6s 102ms/step - loss: 8.1686 - accuracy: 0.0000e+00\n",
      "Epoch 11/70\n",
      "57/57 [==============================] - 6s 104ms/step - loss: 8.1686 - accuracy: 0.0000e+00\n",
      "Epoch 12/70\n",
      "57/57 [==============================] - 6s 105ms/step - loss: 8.1685 - accuracy: 0.0000e+00\n",
      "Epoch 13/70\n",
      "57/57 [==============================] - 6s 103ms/step - loss: 8.1685 - accuracy: 0.0000e+00\n",
      "Epoch 14/70\n",
      "57/57 [==============================] - 6s 103ms/step - loss: 8.1685 - accuracy: 0.0000e+00\n",
      "Epoch 15/70\n",
      "57/57 [==============================] - 6s 104ms/step - loss: 8.1684 - accuracy: 0.0000e+00\n",
      "Epoch 16/70\n",
      "57/57 [==============================] - 6s 102ms/step - loss: 8.1684 - accuracy: 0.0000e+00\n",
      "Epoch 17/70\n",
      "57/57 [==============================] - 6s 102ms/step - loss: 8.1684 - accuracy: 0.0000e+00\n",
      "Epoch 18/70\n",
      "57/57 [==============================] - 6s 103ms/step - loss: 8.1684 - accuracy: 0.0000e+00\n",
      "Epoch 19/70\n",
      "57/57 [==============================] - 6s 103ms/step - loss: 8.1684 - accuracy: 0.0000e+00\n",
      "Epoch 20/70\n",
      "57/57 [==============================] - 6s 102ms/step - loss: 8.1683 - accuracy: 0.0000e+00\n",
      "Epoch 21/70\n",
      "57/57 [==============================] - 6s 102ms/step - loss: 8.1683 - accuracy: 0.0000e+00\n",
      "Epoch 22/70\n",
      "57/57 [==============================] - 6s 102ms/step - loss: 8.1683 - accuracy: 0.0000e+00\n",
      "Epoch 23/70\n",
      "57/57 [==============================] - 6s 102ms/step - loss: 8.1683 - accuracy: 0.0000e+00\n",
      "Epoch 24/70\n",
      "57/57 [==============================] - 6s 104ms/step - loss: 8.1683 - accuracy: 0.0000e+00\n",
      "Epoch 25/70\n",
      "57/57 [==============================] - 6s 103ms/step - loss: 8.1683 - accuracy: 0.0000e+00\n",
      "Epoch 26/70\n",
      "57/57 [==============================] - 6s 102ms/step - loss: 8.1682 - accuracy: 0.0000e+00\n",
      "Epoch 27/70\n",
      "57/57 [==============================] - 6s 103ms/step - loss: 8.1682 - accuracy: 2.8441e-04\n",
      "Epoch 28/70\n",
      "57/57 [==============================] - 6s 102ms/step - loss: 8.1682 - accuracy: 0.0000e+00\n",
      "Epoch 29/70\n",
      "57/57 [==============================] - 6s 102ms/step - loss: 8.1682 - accuracy: 0.0000e+00\n",
      "Epoch 30/70\n",
      "57/57 [==============================] - 6s 104ms/step - loss: 8.1682 - accuracy: 2.8441e-04\n",
      "Epoch 31/70\n",
      "57/57 [==============================] - 6s 102ms/step - loss: 8.1682 - accuracy: 0.0000e+00\n",
      "Epoch 32/70\n",
      "57/57 [==============================] - 6s 103ms/step - loss: 8.1681 - accuracy: 2.8441e-04\n",
      "Epoch 33/70\n",
      "57/57 [==============================] - 6s 102ms/step - loss: 8.1682 - accuracy: 2.8441e-04\n",
      "Epoch 34/70\n",
      "57/57 [==============================] - 6s 103ms/step - loss: 8.1682 - accuracy: 0.0000e+00\n",
      "Epoch 35/70\n",
      "57/57 [==============================] - 6s 103ms/step - loss: 8.1681 - accuracy: 2.8441e-04\n",
      "Epoch 36/70\n",
      "57/57 [==============================] - 6s 104ms/step - loss: 8.1681 - accuracy: 0.0000e+00\n",
      "Epoch 37/70\n",
      "57/57 [==============================] - 6s 102ms/step - loss: 8.1681 - accuracy: 0.0000e+00\n",
      "Epoch 38/70\n",
      "57/57 [==============================] - 6s 103ms/step - loss: 8.1681 - accuracy: 0.0000e+00\n",
      "Epoch 39/70\n",
      "57/57 [==============================] - 7s 116ms/step - loss: 8.1681 - accuracy: 0.0000e+00\n",
      "Epoch 40/70\n",
      "57/57 [==============================] - 7s 123ms/step - loss: 8.1681 - accuracy: 0.0000e+00\n",
      "Epoch 41/70\n",
      "57/57 [==============================] - 7s 115ms/step - loss: 8.1681 - accuracy: 0.0000e+00\n",
      "Epoch 42/70\n",
      "57/57 [==============================] - 7s 115ms/step - loss: 8.1681 - accuracy: 0.0000e+00\n",
      "Epoch 43/70\n",
      "57/57 [==============================] - 7s 119ms/step - loss: 8.1681 - accuracy: 0.0000e+00\n",
      "Epoch 44/70\n",
      "57/57 [==============================] - 7s 122ms/step - loss: 8.1681 - accuracy: 2.8441e-04\n",
      "Epoch 45/70\n",
      "57/57 [==============================] - 7s 119ms/step - loss: 8.1680 - accuracy: 0.0000e+00\n",
      "Epoch 46/70\n",
      "57/57 [==============================] - 7s 115ms/step - loss: 8.1680 - accuracy: 2.8441e-04\n",
      "Epoch 47/70\n",
      "57/57 [==============================] - 7s 115ms/step - loss: 8.1680 - accuracy: 2.8441e-04\n",
      "Epoch 48/70\n",
      "57/57 [==============================] - 7s 115ms/step - loss: 8.1680 - accuracy: 2.8441e-04\n",
      "Epoch 49/70\n",
      "57/57 [==============================] - 7s 114ms/step - loss: 8.1680 - accuracy: 0.0000e+00\n",
      "Epoch 50/70\n",
      "57/57 [==============================] - 7s 115ms/step - loss: 8.1680 - accuracy: 0.0000e+00\n",
      "Epoch 51/70\n",
      "57/57 [==============================] - 7s 115ms/step - loss: 8.1680 - accuracy: 0.0000e+00\n",
      "Epoch 52/70\n",
      "57/57 [==============================] - 7s 115ms/step - loss: 8.1680 - accuracy: 0.0000e+00\n",
      "Epoch 53/70\n",
      "57/57 [==============================] - 7s 118ms/step - loss: 8.1680 - accuracy: 2.8441e-04\n",
      "Epoch 54/70\n",
      "57/57 [==============================] - 7s 120ms/step - loss: 8.1680 - accuracy: 0.0000e+00\n",
      "Epoch 55/70\n",
      "57/57 [==============================] - 7s 120ms/step - loss: 8.1680 - accuracy: 0.0000e+00\n",
      "Epoch 56/70\n",
      "57/57 [==============================] - 7s 114ms/step - loss: 8.1680 - accuracy: 0.0000e+00\n",
      "Epoch 57/70\n",
      "57/57 [==============================] - 7s 114ms/step - loss: 8.1680 - accuracy: 0.0000e+00\n",
      "Epoch 58/70\n",
      "57/57 [==============================] - 7s 114ms/step - loss: 8.1680 - accuracy: 0.0000e+00\n",
      "Epoch 59/70\n",
      "57/57 [==============================] - 7s 114ms/step - loss: 8.1680 - accuracy: 2.8441e-04\n",
      "Epoch 60/70\n",
      "57/57 [==============================] - 7s 115ms/step - loss: 8.1680 - accuracy: 0.0000e+00\n",
      "Epoch 61/70\n",
      "57/57 [==============================] - 7s 114ms/step - loss: 8.1680 - accuracy: 0.0000e+00\n",
      "Epoch 62/70\n",
      "57/57 [==============================] - 7s 117ms/step - loss: 8.1680 - accuracy: 2.8441e-04\n",
      "Epoch 63/70\n",
      "57/57 [==============================] - 7s 114ms/step - loss: 8.1680 - accuracy: 2.8441e-04\n",
      "Epoch 64/70\n",
      "57/57 [==============================] - 7s 114ms/step - loss: 8.1680 - accuracy: 0.0000e+00\n",
      "Epoch 65/70\n",
      "57/57 [==============================] - 7s 115ms/step - loss: 8.1680 - accuracy: 0.0000e+00\n",
      "Epoch 66/70\n",
      "57/57 [==============================] - 7s 114ms/step - loss: 8.1680 - accuracy: 0.0000e+00\n",
      "Epoch 67/70\n",
      "57/57 [==============================] - 7s 114ms/step - loss: 8.1679 - accuracy: 0.0000e+00\n",
      "Epoch 68/70\n",
      "57/57 [==============================] - 6s 114ms/step - loss: 8.1679 - accuracy: 0.0000e+00\n",
      "Epoch 69/70\n",
      "57/57 [==============================] - 7s 117ms/step - loss: 8.1679 - accuracy: 2.8441e-04\n",
      "Epoch 70/70\n",
      "57/57 [==============================] - 7s 114ms/step - loss: 8.1679 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c95af53e20>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,batch_size=62,epochs=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d52a6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For preprocessing input text for test\n",
    "def preprocess(text):\n",
    "    soup1=BeautifulSoup(text,'html.parser')#remove html tag using beautifulsoup\n",
    "    non_html_txt=soup.get_text()\n",
    "    \n",
    "    #remove unwanted charectors and symbols\n",
    "    text=re.sub('[^a-zA-Z0-9\\s]',' ',non_html_txt)\n",
    "    text = text.replace('\\n', '').replace('\\r', '').replace('\\ufeff', '')\n",
    "\n",
    "    #remove extra spaces\n",
    "    z = []\n",
    "    for i in text.split():\n",
    "        if i not in z:\n",
    "            z.append(i)  \n",
    "    text = ' '.join(z)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97b2e23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It gives single predicted words\n",
    "def predict_nxt_word(txt):\n",
    "#      \n",
    "    \n",
    "    tok_text = tokenizer.texts_to_sequences([ txt])\n",
    "#     print(tok_text)\n",
    "    preds = model.predict(np.array(tok_text), verbose=0)[0]\n",
    "    next_word = tokenizer.sequences_to_texts([[np.argmax(preds)]])[0]\n",
    "    return next_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53dbf11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It gives 5 predicted words\n",
    "\n",
    "def predict_nxt_words1(txt, k=5):\n",
    "    tok_text = tokenizer.texts_to_sequences([txt])\n",
    "    preds = model.predict(np.array(tok_text), verbose=0)[0]\n",
    "    top_k_indices = preds.argsort()[-k:][::-1]\n",
    "    top_k_words = [tokenizer.sequences_to_texts([[i]])[0] for i in top_k_indices]\n",
    "    return top_k_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5011481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Rue this code\n",
    "\n",
    "\n",
    "# while(True):\n",
    "#     text=input('Enter Text or 0 for exit=')\n",
    "#     if text=='0':\n",
    "#         print('Exited')\n",
    "#         break\n",
    "#     else:\n",
    "#         try:\n",
    "#             text=preprocess(text)\n",
    "#             text=text.split()\n",
    "#             print(predict_nxt_words1(text[-3:]))\n",
    "#         except Exception as e:\n",
    "#             print('Error',e)\n",
    "#             continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79bd3660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['178', '29000', '67100', '216', '440040']\n"
     ]
    }
   ],
   "source": [
    "txt='i took me'\n",
    "txt=preprocess(txt)\n",
    "txt=txt.split(' ')\n",
    "txt=txt[-3:]\n",
    "# print(txt)\n",
    "nxt=predict_nxt_words1(txt)\n",
    "print(nxt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a9b9f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
